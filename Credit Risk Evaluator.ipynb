{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>...</th>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "      <th>tot_hi_cred_lim</th>\n",
       "      <th>total_bal_ex_mort</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>total_il_high_credit_limit</th>\n",
       "      <th>hardship_flag</th>\n",
       "      <th>debt_settlement_flag</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000.0</td>\n",
       "      <td>0.1894</td>\n",
       "      <td>256.38</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>n</td>\n",
       "      <td>28.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>87.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>352260.0</td>\n",
       "      <td>62666.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>low_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40000.0</td>\n",
       "      <td>0.1614</td>\n",
       "      <td>975.71</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>102000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>n</td>\n",
       "      <td>11.72</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294664.0</td>\n",
       "      <td>109911.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>71044.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>low_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11000.0</td>\n",
       "      <td>0.2055</td>\n",
       "      <td>294.81</td>\n",
       "      <td>RENT</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>Verified</td>\n",
       "      <td>n</td>\n",
       "      <td>37.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92228.0</td>\n",
       "      <td>36007.0</td>\n",
       "      <td>33000.0</td>\n",
       "      <td>46328.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>low_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.1612</td>\n",
       "      <td>140.87</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>38000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>n</td>\n",
       "      <td>42.89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>284273.0</td>\n",
       "      <td>52236.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>52017.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>low_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14000.0</td>\n",
       "      <td>0.1797</td>\n",
       "      <td>505.93</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>43000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>n</td>\n",
       "      <td>22.16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120280.0</td>\n",
       "      <td>88147.0</td>\n",
       "      <td>33300.0</td>\n",
       "      <td>78680.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>low_risk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  int_rate  installment home_ownership  annual_inc  \\\n",
       "0     7000.0    0.1894       256.38       MORTGAGE     75000.0   \n",
       "1    40000.0    0.1614       975.71       MORTGAGE    102000.0   \n",
       "2    11000.0    0.2055       294.81           RENT     45000.0   \n",
       "3     4000.0    0.1612       140.87       MORTGAGE     38000.0   \n",
       "4    14000.0    0.1797       505.93       MORTGAGE     43000.0   \n",
       "\n",
       "  verification_status pymnt_plan    dti  delinq_2yrs  inq_last_6mths  ...  \\\n",
       "0        Not Verified          n  28.62          0.0             2.0  ...   \n",
       "1     Source Verified          n  11.72          2.0             0.0  ...   \n",
       "2            Verified          n  37.25          1.0             3.0  ...   \n",
       "3        Not Verified          n  42.89          1.0             0.0  ...   \n",
       "4     Source Verified          n  22.16          1.0             0.0  ...   \n",
       "\n",
       "   percent_bc_gt_75  pub_rec_bankruptcies  tax_liens  tot_hi_cred_lim  \\\n",
       "0              87.5                   0.0        0.0         352260.0   \n",
       "1               0.0                   0.0        0.0         294664.0   \n",
       "2               7.7                   0.0        0.0          92228.0   \n",
       "3             100.0                   0.0        0.0         284273.0   \n",
       "4              25.0                   0.0        0.0         120280.0   \n",
       "\n",
       "  total_bal_ex_mort  total_bc_limit  total_il_high_credit_limit  \\\n",
       "0           62666.0         35000.0                     10000.0   \n",
       "1          109911.0          9000.0                     71044.0   \n",
       "2           36007.0         33000.0                     46328.0   \n",
       "3           52236.0         13500.0                     52017.0   \n",
       "4           88147.0         33300.0                     78680.0   \n",
       "\n",
       "   hardship_flag  debt_settlement_flag    target  \n",
       "0              N                     N  low_risk  \n",
       "1              N                     N  low_risk  \n",
       "2              N                     N  low_risk  \n",
       "3              N                     N  low_risk  \n",
       "4              N                     N  low_risk  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV\n",
    "train_df = pd.read_csv(Path('data/2019loans.csv'))\n",
    "test_df = pd.read_csv(Path('data/2020Q1loans.csv'))\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric and separate target feature for training data\n",
    "y_train = train_df['target']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "y_train_label = LabelEncoder().fit_transform(train_df['target'])\n",
    "\n",
    "x_train = train_df.drop(columns = ['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric and separate target feature for testing data\n",
    "y_test = test_df['target']\n",
    "y_test_label = LabelEncoder().fit_transform(test_df['target'])\n",
    "x_test = test_df.drop(columns = ['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing: Convert categorical data to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add missing dummy variables to testing set\n",
    "x_train_dummies = pd.get_dummies(x_train)\n",
    "x_test_dummies = pd.get_dummies(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in missing categories in the testing set\n",
    "for column in x_train_dummies.columns:\n",
    "    if column not in x_test_dummies.columns:\n",
    "        x_test_dummies[column]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prediction - Logistic Regression vs. Random Forest (unscaled)\n",
    "\n",
    "# The dataset we are using is highly categorical and non-linear. \n",
    "# Linear relationships are best used with logistic regression.\n",
    "# Datasets with non-linear relationships operate best with random forest for a balance between precision and overfitting.\n",
    "# The prediction would be that in this case, the random forest model will be more accurate compared to a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.6528735632183909\n",
      "Testing Data Score: 0.5095703955763505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the unscaled data and print the model score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier_lr = LogisticRegression()\n",
    "classifier_lr.fit(x_train_dummies, y_train_label)\n",
    "\n",
    "print(f\"Training Data Score: {classifier_lr.score(x_train_dummies, y_train_label)}\")\n",
    "print(f\"Testing Data Score: {classifier_lr.score(x_test_dummies, y_test_label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 1.0\n",
      "Testing Score: 0.646958740961293\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier_rf = RandomForestClassifier(random_state=1, n_estimators=500).fit(x_train_dummies, y_train_label)\n",
    "\n",
    "print(f'Training Score: {classifier_rf.score(x_train_dummies, y_train_label)}')\n",
    "print(f'Testing Score: {classifier_rf.score(x_test_dummies, y_test_label)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Results - Logistic Regression vs. Random Forest (unscaled)\n",
    "\n",
    "# The random forest model yielded a score of 0.64 compared to the logistic regression model score of 0.51.\n",
    "# The result was in line with the initial prediction of a random forest being more accurate in this particular dataset for the non-linear relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(x_train_dummies)\n",
    "x_train_dummies_scaled = scaler.transform(x_train_dummies)\n",
    "x_test_dummies_scaled = scaler.transform(x_test_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prediction - Logistic Regression vs. Random Forest (scaled)\n",
    "\n",
    "# Random forest models do not require the data to be scaled and so will not see much of a change from the data being scaled.\n",
    "# Logistic regression models will see an improved score from the scaling of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.710919540229885\n",
      "Testing Data Score: 0.7598894087622289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the scaled data and print the model score\n",
    "classifier_lr = LogisticRegression()\n",
    "classifier_lr.fit(x_train_dummies_scaled, y_train_label)\n",
    "\n",
    "print(f\"Training Data Score: {classifier_lr.score(x_train_dummies_scaled, y_train_label)}\")\n",
    "print(f\"Testing Data Score: {classifier_lr.score(x_test_dummies_scaled, y_test_label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 1.0\n",
      "Testing Score: 0.6480221182475542\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model on the scaled data and print the model score\n",
    "classifier_rf = RandomForestClassifier(random_state=1, n_estimators=500).fit(x_train_dummies_scaled, y_train_label)\n",
    "\n",
    "print(f'Training Score: {classifier_rf.score(x_train_dummies_scaled, y_train_label)}')\n",
    "print(f'Testing Score: {classifier_rf.score(x_test_dummies_scaled, y_test_label)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Results - Logistic Regression vs. Random Forest (scaled)\n",
    "\n",
    "# The random forest model yielded the same test score result as with the unscaled dataset.\n",
    "# The logistic regression model shows a test score improvement of 0.25.\n",
    "# The results are in line with the initial prediction that scaling has a significant impact on logistic regression models, with little to no impact on random forest models.\n",
    "# With an unscaled dataset, the random forest was resulting in a higher test score compared to logistic regression.\n",
    "# However, after scaling, logistic regression yielded a higher result than random forest, showing that a properly scaled data on a simpler model could be more effective than complex decision tree models like random forests."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
